# ‚úÖ Complete Testing Checklist - DataQuarantine System

Use this checklist to verify every component of your system is working correctly.

---

## üéØ Before You Start

- [ ] All Docker containers are running: `docker ps` (should show 8 containers)
- [ ] No containers are restarting (check "Status" column)
- [ ] Frontend is running on http://localhost:3000 ‚úÖ
- [ ] API is running on http://localhost:8080 ‚úÖ

---

## 1Ô∏è‚É£ Frontend (http://localhost:3000)

### Visual Checks:
- [ ] Page loads without errors
- [ ] All UI elements are visible (buttons, forms, navigation)
- [ ] No broken images or icons
- [ ] Styling looks correct (colors, spacing, fonts)

### Functional Checks:
- [ ] Can navigate between pages
- [ ] Forms accept input
- [ ] Buttons respond to clicks
- [ ] Data displays from backend (if applicable)

### Developer Console (Press F12):
- [ ] **Console tab**: No critical errors (some warnings are okay)
- [ ] **Network tab**: API calls return 200/201 status codes
- [ ] **Network tab**: No failed requests (red entries)

**What to Look For:**
- ‚úÖ Green checkmarks in Network tab
- ‚úÖ Fast loading times (< 3 seconds)
- ‚ùå Red errors in Console
- ‚ùå 404, 500 status codes in Network

---

## 2Ô∏è‚É£ API Backend (http://localhost:8080)

### API Documentation:
- [ ] Visit http://localhost:8080/docs
- [ ] Swagger UI loads with all endpoints listed
- [ ] Can expand endpoint sections (GET, POST, etc.)

### Test Endpoints:
1. **Health Check** (if available):
   - [ ] Visit http://localhost:8080/health or /api/health
   - [ ] Should return: `{"status": "healthy"}` or similar

2. **GET Endpoint** (e.g., list quarantine records):
   - [ ] Click "Try it out" in Swagger UI
   - [ ] Click "Execute"
   - [ ] Response Code: 200
   - [ ] Response Body: JSON array/object (may be empty if no data)

3. **POST Endpoint** (if testing data submission):
   - [ ] Fill in required fields
   - [ ] Click "Execute"
   - [ ] Response Code: 201 (Created) or 200 (OK)
   - [ ] Response Body: Confirmation message

### API Logs:
```bash
docker logs dataquarantine-api --tail 50
```

**What to Look For:**
- ‚úÖ "Application startup complete" or similar message
- ‚úÖ "Connected to database" message
- ‚úÖ "Connected to Kafka" message
- ‚ùå Python exceptions/stack traces
- ‚ùå "Connection refused" errors

---

## 3Ô∏è‚É£ Kafka UI (http://localhost:8090)

### Cluster Health:
- [ ] Go to **Dashboard** or **Clusters**
- [ ] Cluster name: "dataquarantine-cluster"
- [ ] Status: Online/Healthy (green indicator)

### Brokers:
- [ ] Go to **Brokers** tab
- [ ] Should see: 1 broker (kafka:29092)
- [ ] Status: Running

### Topics:
- [ ] Go to **Topics** tab
- [ ] Should see topics like:
  - [ ] `quarantine-events`
  - [ ] `data-validation`
  - [ ] `audit-logs` (names may vary)

**For Each Topic:**
- [ ] Click on topic name
- [ ] Check **Partitions**: Usually 1 for local dev
- [ ] Check **Messages**: May be 0 if no data processed yet
- [ ] Go to **Messages** tab ‚Üí Click "Fetch Messages"
- [ ] Should see JSON messages (or empty if system just started)

### Consumer Groups:
- [ ] Go to **Consumers** tab
- [ ] Should see consumer groups (if API is consuming messages)
- [ ] **Lag**: Should be 0 or very low (< 10)

**What to Look For:**
- ‚úÖ All topics created
- ‚úÖ Messages incrementing over time (if system is active)
- ‚úÖ Consumer lag = 0 or low
- ‚ùå No topics found
- ‚ùå High consumer lag (> 1000)

---

## 4Ô∏è‚É£ MinIO Console (http://localhost:9001)

### Login:
- [ ] Username: `minioadmin`
- [ ] Password: `minioadmin`
- [ ] Successfully logged in

### Buckets:
- [ ] Go to **Object Browser** (left menu)
- [ ] Should see buckets like:
  - [ ] `quarantine`
  - [ ] `validated-data`
  - [ ] `rejected-data` (names may vary based on your config)

**For Each Bucket:**
- [ ] Click on bucket name
- [ ] May see folders organized by date (e.g., `2025/12/29/`)
- [ ] May see files (CSV, JSON, etc.) if system has processed data
- [ ] Click on a file to preview or download

### Access Keys:
- [ ] Go to **Identity** ‚Üí **Service Accounts** (left menu)
- [ ] Should see access keys used by the API
- [ ] Verify keys match your `.env` or `docker-compose.yml`

### Monitoring:
- [ ] Go to **Metrics** (left menu)
- [ ] Check **Total Storage**: Should show used space
- [ ] Check **API Calls**: Should increment if API is accessing storage

**What to Look For:**
- ‚úÖ Buckets created (may be auto-created on first use)
- ‚úÖ Files organized by date/time
- ‚úÖ Can preview/download files
- ‚ùå "Access Denied" errors
- ‚ùå Buckets missing

---

## 5Ô∏è‚É£ Grafana (http://localhost:3001)

### Login:
- [ ] Username: `admin`
- [ ] Password: `admin`
- [ ] You'll be prompted to change password (can skip for now)

### Data Source:
- [ ] Go to **Configuration** ‚Üí **Data Sources** (left menu)
- [ ] Click on "Prometheus"
- [ ] Scroll down and click **Test**
- [ ] Should say: "Data source is working"

### Dashboards:
- [ ] Go to **Dashboards** (left menu, four-squares icon)
- [ ] Look for DataQuarantine dashboards (if pre-configured)
- [ ] Click on a dashboard

**What to Check on Dashboards:**
- [ ] Graphs are loading (not just "No data")
- [ ] Time range is set appropriately (top-right, try "Last 1 hour")
- [ ] Metrics are showing:
  - [ ] API request rate
  - [ ] Error rate (should be very low)
  - [ ] Database connections
  - [ ] Kafka message throughput

### Explore (Manual Query):
- [ ] Go to **Explore** (left menu, compass icon)
- [ ] Data source: Prometheus
- [ ] Enter query: `up`
- [ ] Click **Run Query** (top-right)
- [ ] Should see services with value `1` (up) or `0` (down)

**Try These Queries:**
```promql
# All services status
up

# API specific
up{job="api"}

# HTTP requests total
http_requests_total

# Database connections
pg_stat_database_numbackends
```

**What to Look For:**
- ‚úÖ Data source connected
- ‚úÖ Graphs showing data
- ‚úÖ Services showing as "up" (value = 1)
- ‚ùå "No data" errors
- ‚ùå All services showing value = 0

---

## 6Ô∏è‚É£ Prometheus (http://localhost:9090)

### Targets:
- [ ] Go to **Status** ‚Üí **Targets** (top menu)
- [ ] Should see all monitored services
- [ ] Each target should have:
  - [ ] State: **UP** (green)
  - [ ] Last Scrape: < 30 seconds ago
  - [ ] Health: No errors

**Common Targets:**
- [ ] `api` - Your FastAPI backend
- [ ] `kafka` - Kafka metrics exporter (if configured)
- [ ] `postgres` - PostgreSQL exporter (if configured)

### Graph:
- [ ] Go to **Graph** tab (top menu)
- [ ] Enter query: `up`
- [ ] Click **Execute**
- [ ] Switch to **Graph** tab (below query box)
- [ ] Should see line graph with values at 1 for all services

**Try These Queries:**
```promql
# API health
up{job="api"}

# Total HTTP requests
http_requests_total

# Request duration
http_request_duration_seconds

# Active database connections
pg_stat_activity_count
```

**What to Look For:**
- ‚úÖ All targets showing "UP" in green
- ‚úÖ Recent scrape times (< 30 sec)
- ‚úÖ Queries returning data
- ‚ùå Targets showing "DOWN" in red
- ‚ùå "Context deadline exceeded" errors

---

## 7Ô∏è‚É£ PostgreSQL (DBeaver)

### Connection:
- [ ] Open DBeaver
- [ ] Create new connection (PostgreSQL)
- [ ] Enter details:
  - Host: `localhost`
  - Port: `5432`
  - Database: `dataquarantine`
  - Username: `quarantine_user`
  - Password: `quarantine_pass`
- [ ] Test Connection ‚Üí Should succeed
- [ ] Click Finish

### Database Structure:
- [ ] Expand **dataquarantine** ‚Üí **Schemas** ‚Üí **public** ‚Üí **Tables**
- [ ] Should see tables like:
  - [ ] `quarantine_records`
  - [ ] `validation_rules`
  - [ ] `audit_logs`
  - [ ] Others based on your schema

### Table Contents:
For each table:
- [ ] Right-click ‚Üí **View Data**
- [ ] Should see columns and rows (may be empty if no data yet)

### Run Test Queries:

**1. List all tables:**
```sql
SELECT table_name 
FROM information_schema.tables 
WHERE table_schema = 'public'
ORDER BY table_name;
```
- [ ] Query executes successfully
- [ ] Returns list of tables

**2. Count records:**
```sql
SELECT COUNT(*) FROM quarantine_records;
```
- [ ] Query executes successfully
- [ ] Returns a number (may be 0)

**3. View recent records:**
```sql
SELECT * FROM quarantine_records 
ORDER BY created_at DESC 
LIMIT 10;
```
- [ ] Query executes successfully
- [ ] Returns up to 10 rows (if data exists)

**4. Check schema:**
```sql
SELECT column_name, data_type 
FROM information_schema.columns 
WHERE table_name = 'quarantine_records'
ORDER BY ordinal_position;
```
- [ ] Query executes successfully
- [ ] Returns column definitions

**What to Look For:**
- ‚úÖ Connection successful
- ‚úÖ Tables exist
- ‚úÖ Queries execute without errors
- ‚úÖ Data types match expectations
- ‚ùå "relation does not exist" errors
- ‚ùå "password authentication failed"

---

## 8Ô∏è‚É£ Integration Flow Test

This tests the entire data flow from end to end.

### Test Setup:
1. **Clear Previous Data** (optional):
   ```sql
   TRUNCATE TABLE quarantine_records;
   ```

2. **Prepare Test Data**:
   - Create a sample CSV or JSON file with intentionally bad data
   - Or use Swagger UI to submit test data via POST endpoint

### Test Execution:

**Step 1: Submit Data**
- [ ] Send data via Frontend UI or API (Swagger UI)
- [ ] Check response: Should be 200/201
- [ ] Note any returned ID or reference

**Step 2: Check Kafka**
- [ ] Go to Kafka UI ‚Üí Topics ‚Üí `quarantine-events`
- [ ] Click **Messages** tab ‚Üí **Fetch Messages**
- [ ] Should see new message with your test data
- [ ] Message timestamp should match submission time

**Step 3: Check Database**
- [ ] In DBeaver, run:
   ```sql
   SELECT * FROM quarantine_records 
   ORDER BY created_at DESC 
   LIMIT 5;
   ```
- [ ] Should see your test record
- [ ] Verify fields are populated correctly
- [ ] Check `status` field (e.g., "quarantined", "pending")

**Step 4: Check Storage (MinIO)**
- [ ] Go to MinIO Console ‚Üí Buckets ‚Üí `quarantine`
- [ ] Navigate to today's folder (e.g., `2025/12/29/`)
- [ ] Should see a file related to your test data
- [ ] Download and verify contents

**Step 5: Check Metrics**
- [ ] Go to Prometheus ‚Üí Graph
- [ ] Query: `http_requests_total{endpoint="/quarantine"}`
- [ ] Should show counter has increased
- [ ] Go to Grafana ‚Üí Check relevant dashboard
- [ ] Should see spike in request graph

**What to Look For:**
- ‚úÖ Data flows from Frontend ‚Üí API ‚Üí Kafka ‚Üí Database ‚Üí MinIO
- ‚úÖ Each step completes within seconds
- ‚úÖ Metrics update in Prometheus/Grafana
- ‚ùå Data missing at any step
- ‚ùå Errors in logs

---

## üîç Final System Health Check

Run this after completing all above tests:

### Docker Health:
```bash
docker ps --format "table {{.Names}}\t{{.Status}}"
```
- [ ] All 8 containers show "Up" status
- [ ] No "(unhealthy)" status
- [ ] No "(restarting)" loops

### Service Health:
- [ ] API: http://localhost:8080/docs ‚Üí Loads
- [ ] Frontend: http://localhost:3000 ‚Üí Loads
- [ ] Kafka UI: http://localhost:8090 ‚Üí Shows cluster online
- [ ] Grafana: http://localhost:3001 ‚Üí Dashboards load
- [ ] MinIO: http://localhost:9001 ‚Üí Console loads
- [ ] Prometheus: http://localhost:9090/targets ‚Üí All targets UP

### Logs Review:
```bash
docker-compose logs --tail=20 api
```
- [ ] No ERROR level messages in last 20 lines
- [ ] No stack traces

### Database Connectivity:
- [ ] DBeaver connection still active
- [ ] Can run queries without timeout

---

## üìä Expected Results Summary

| Component | Expected State |
|-----------|----------------|
| **Containers** | 8 running, 0 unhealthy |
| **Frontend** | Loads in < 3 seconds |
| **API** | Responds in < 1 second |
| **Kafka Topics** | 3+ topics created |
| **Kafka Messages** | Incrementing (if active) |
| **MinIO Buckets** | 2-3 buckets exist |
| **Database Tables** | 5+ tables exist |
| **Prometheus Targets** | All UP (green) |
| **Grafana Dashboards** | Showing data |

---

## üö® If Tests Fail

### General Approach:
1. **Note what failed**: Write down the exact error message
2. **Check logs**: `docker logs <container-name> --tail 50`
3. **Verify dependencies**: Is the required service running?
4. **Restart service**: `docker-compose restart <service-name>`
5. **Full restart**: `docker-compose down && docker-compose up -d`

### Specific Failures:

**"Can't connect to database"**
‚Üí Check Postgres: `docker logs dataquarantine-postgres`

**"Kafka not responding"**
‚Üí Wait 2 minutes (Kafka is slow to start)
‚Üí Check: `docker logs dataquarantine-kafka`

**"API returns 500"**
‚Üí Check API logs: `docker logs dataquarantine-api`
‚Üí Look for Python exceptions

**"No data in Grafana"**
‚Üí Change time range to "Last 15 minutes"
‚Üí Check Prometheus targets are UP

**"MinIO access denied"**
‚Üí Verify credentials: minioadmin/minioadmin
‚Üí Check API has correct MinIO env vars

---

## ‚úÖ All Tests Passed?

**Congratulations!** üéâ Your DataQuarantine system is fully operational!

### Next Steps:
1. **Process Real Data**: Try uploading actual data files
2. **Monitor Performance**: Watch metrics in Grafana over time
3. **Explore Features**: Test different validation rules
4. **Build Dashboards**: Create custom Grafana dashboards
5. **Learn Tools**: Dive deeper into Kafka, MinIO, etc.

---

## üìö Need Help?

- **See detailed guides**: `BEGINNER_GUIDE.md`
- **Quick commands**: `QUICK_REFERENCE.md`
- **Troubleshooting**: Check container logs first
- **Community**: Search for specific error messages online

---

**Last Updated**: 2025-12-29
**System Version**: DataQuarantine POC v1.0
